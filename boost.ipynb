{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df_train = read_csv('train.csv')\n",
    "df_test = read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`opened_position_qty ` and `closed_position_qty` are sometimes empty, but we can derive them from other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_position_qty_columns(df):\n",
    "    df['opened_position_qty '] = (df['transacted_qty']+df['d_open_interest'])/2\n",
    "    df['closed_position_qty'] = (df['transacted_qty']-df['d_open_interest'])/2\n",
    "fix_position_qty_columns(df_train)\n",
    "fix_position_qty_columns(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "From Kaggle, the starting features are:\n",
    "- `id` - The timestep ID of the order book features. In the training set, id is ordered chronologically. However, in the test set, they are scrambled so that you cannot simply use the order book features of future data to make fake \"predictions\" in previous timesteps. To keep the competition more of a ML problem and less of a math problem, this scrambling also prevents timeseries modelling. If you would like, you could try to unscramble the ordering using some ML.\n",
    "- `last_price` - the price at which the most recent order fill occurred.\n",
    "- `mid` - the \"mid\" price, which is the average of the best bid (bid1) and the best ask (ask1) prices.\n",
    "- `opened_position_qty ` - In the past 500ms, how many buy orders were filled?\n",
    "- `closed_position_qty` - In the past 500ms, how many sell orders were filled?\n",
    "- `transacted_qty` - In the past 500ms, how many buy+sell orders were filled?\n",
    "- `d_open_interest` - In the past 500ms, what is (#buy orders filled)- (#sell orders filled)?\n",
    "- `bid1` - What is the 1st bid price (the best/highest one)?\n",
    "- `bid[2,3,4,5]` - What is the [2nd, 3rd, 4th, 5th] best/highest bid price?\n",
    "- `ask1` - What is the 1st ask price (the best/lowest/cheapest one)?\n",
    "- `ask[2,3,4,5]` - What is the [2nd, 3rd, 4th, 5th] best/lowest/cheapest ask price?\n",
    "- `bid1vol` - What is the quantity of contracts in the order book at the 1st bid price (the best/highest one)?\n",
    "- `bid[2,3,4,5]vol` - What is the quantity of contracts in the order book at the [2,3,4,5]th bid price (the [2,3,4,5]th best/highest one)?\n",
    "- `ask1vol` - What is the quantity of contracts in the order book at the 1st ask price (the best/lowest/cheapest one)?\n",
    "- `ask[2,3,4,5]vol` - What is the quantity of contracts in the order book at the [2,3,4,5]th ask price (the [2,3,4,5]th best/lowest/cheapest one)?\n",
    "- `y` (unique to training data) - What is the change in the mid price from now to 2 timesteps (approx. 1 second) in the future? \"1\" means this change is strictly positive, and \"0\" means the change is 0 or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def add_features(df):\n",
    "    for i in range(1,6):\n",
    "        for n in ('bid', 'ask'):\n",
    "            df[f'{n}{i}mul'] = df[f'{n}{i}'] * df[f'{n}{i}vol']\n",
    "    df['lpdm'] = df['last_price']/df['mid']\n",
    "    df['spread'] = df['ask1']-df['bid1']\n",
    "    bidvol = df['bid1vol']\n",
    "    askvol = df['ask1vol']\n",
    "    for i in range(2,6):\n",
    "        bidvol += df[f'bid{i}vol']\n",
    "        askvol += df[f'ask{i}vol']\n",
    "    df['buy_fill_prop'] = df['opened_position_qty ']/bidvol\n",
    "    df['sell_fill_prop'] = df['closed_position_qty']/askvol\n",
    "    df['bid_ask_ratio'] = bidvol/askvol\n",
    "\n",
    "def add_features2(df):\n",
    "    cols = copy.copy(df.columns)\n",
    "    for i in range(len(cols)-1):\n",
    "        n1 = cols[i]\n",
    "        if n1 in ('id', 'y'):\n",
    "            continue\n",
    "        for j in range(i+1, len(cols)):\n",
    "            n2 = cols[j]\n",
    "            if n2 in ('id', 'y'):\n",
    "                continue\n",
    "            p = f'{i},{j},'\n",
    "            df[f'{p}*'] = df[n1]*df[n2]\n",
    "            df[f'{p}/'] = df[n1]/df[n2]\n",
    "    \n",
    "add_features2(df_train)\n",
    "add_features2(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trainlen = 100000\n",
    "fsz = trainlen//20\n",
    "gap = 200000\n",
    "\n",
    "idx_folds = [(np.concatenate((np.arange(0, i*fsz), np.arange((i+1)*fsz, trainlen))),\n",
    "                 np.arange(i*fsz, (i+1)*fsz))\n",
    "                for i in range(20)]\n",
    "\n",
    "df_train_lean = df_train.drop(columns=['id', 'y']).to_numpy()\n",
    "df_train_y = df_train['y'].to_numpy()\n",
    "\n",
    "test_x = df_test.drop(columns='id').to_numpy()\n",
    "test_id = df_test['id']\n",
    "\n",
    "# 'global' validation set, never used for training\n",
    "g_val_x = df_train_lean[trainlen+gap:,:]\n",
    "g_val_y = df_train_y[trainlen+gap:]\n",
    "\n",
    "# 'global' training set, includes cross-validation sets\n",
    "g_train_x = df_train_lean[:trainlen,:]\n",
    "g_train_y = df_train_y[:trainlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msbauer/.local/lib/python3.6/site-packages/numpy/core/_methods.py:117: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/home/msbauer/miniconda3/envs/cs155/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in subtract\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/msbauer/miniconda3/envs/cs155/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in subtract\n",
      "  after removing the cwd from sys.path.\n",
      "/home/msbauer/miniconda3/envs/cs155/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in subtract\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "col_stds = np.std(df_train_lean, 0)\n",
    "\n",
    "g_train_x = (g_train_x-np.mean(g_train_x, 0))/col_stds\n",
    "g_val_x = (g_val_x-np.mean(g_val_x, 0))/col_stds\n",
    "test_x = (test_x-np.mean(test_x, 0))/col_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training XGBoost Models\n",
    "- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 finished: local val=0.6446323230992738, global val=0.6529872991891376\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bd441bae065b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     bst = xgb.train(xgb_params, dtrain, 100,\n\u001b[1;32m     26\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'local-val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgb_dgval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     early_stopping_rounds=20, verbose_eval=False)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mxgb_ypred_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mxgb_ypred_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_dgval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs155/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs155/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs155/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_params = {\n",
    "    'eval_metric' : 'auc',\n",
    "    'objective' : 'binary:logistic',\n",
    "    'max_depth' : 3,\n",
    "    'learning_rate' : 0.15,\n",
    "    'subsample' : 0.5,\n",
    "    'colsample_bytree' : 0.5,\n",
    "}\n",
    "\n",
    "xgb_ypred_train = np.zeros((len(g_train_y), len(idx_folds)))\n",
    "xgb_ypred_val = np.zeros((len(g_val_y), len(idx_folds)))\n",
    "xgb_ypred_test = np.zeros((len(test_id), len(idx_folds)))\n",
    "\n",
    "xgb_dgval = xgb.DMatrix(g_val_x, label=g_val_y)\n",
    "xgb_dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "fi = None\n",
    "\n",
    "for f, (idx_train, idx_val) in enumerate(idx_folds):\n",
    "    dtrain = xgb.DMatrix(g_train_x[idx_train], label=g_train_y[idx_train])\n",
    "    dval = xgb.DMatrix(g_train_x[idx_val], label=g_train_y[idx_val])\n",
    "    bst = xgb.train(xgb_params, dtrain, 100,\n",
    "                    [(dtrain, 'train'), (dval, 'local-val'), (xgb_dgval, 'eval')],\n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    xgb_ypred_train[idx_val,f] = bst.predict(dval)\n",
    "    xgb_ypred_val[:,f] = bst.predict(xgb_dgval)\n",
    "    xgb_ypred_test[:,f] = bst.predict(xgb_dtest)\n",
    "    auc_local = roc_auc_score(g_train_y[idx_val], xgb_ypred_train[idx_val,f])\n",
    "    auc_global = roc_auc_score(g_val_y, xgb_ypred_val[:,f])\n",
    "    print(f'Fold {f+1} finished: local val={auc_local}, global val={auc_global}')\n",
    "    fi = bst.get_score(importance_type='gain')\n",
    "\n",
    "xgb_val_score = roc_auc_score(g_val_y, np.mean(xgb_ypred_val, 1))\n",
    "print(f'Ensemble score (pred. means): {xgb_val_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Ridge Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-979b6eae3a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_train_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mridge_ypred_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mridge_ypred_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_val_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    545\u001b[0m                          \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_ypred_train = np.zeros((len(g_train_y), len(idx_folds)))\n",
    "ridge_ypred_val = np.zeros((len(g_val_y), len(idx_folds)))\n",
    "ridge_ypred_test = np.zeros((len(test_id), len(idx_folds)))\n",
    "\n",
    "for f, (idx_train, idx_val) in enumerate(idx_folds):\n",
    "    ridge.fit(g_train_x[idx_train], g_train_y[idx_train])\n",
    "    ridge_ypred_train[idx_val,f] = sigmoid(ridge.predict(g_train_x[idx_val]))\n",
    "    ridge_ypred_val[:,f] = sigmoid(ridge.predict(g_val_x))\n",
    "    ridge_ypred_test[:,f] = sigmoid(ridge.predict(test_x))\n",
    "    auc_local = roc_auc_score(g_train_y[idx_val], ridge_ypred_train[idx_val,f])\n",
    "    auc_global = roc_auc_score(g_val_y, ridge_ypred_val[:,f])\n",
    "    print(f'Fold {f+1} finished: local val={auc_local}, global val={auc_global}')\n",
    "\n",
    "ridge_val_score = roc_auc_score(g_val_y, np.mean(ridge_ypred_val, 1))\n",
    "print(f'Ensemble score (pred. means): {ridge_val_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.514782\teval-auc:0.624998\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 15 rounds.\n",
      "[10]\ttrain-auc:0.573696\teval-auc:0.64742\n",
      "[20]\ttrain-auc:0.5932\teval-auc:0.652541\n",
      "[30]\ttrain-auc:0.595401\teval-auc:0.652629\n",
      "[40]\ttrain-auc:0.601448\teval-auc:0.652726\n",
      "[50]\ttrain-auc:0.602061\teval-auc:0.65289\n",
      "[60]\ttrain-auc:0.602966\teval-auc:0.65287\n",
      "Stopping. Best iteration:\n",
      "[48]\ttrain-auc:0.601867\teval-auc:0.652894\n",
      "\n",
      "Score: 0.6528587130315405\n"
     ]
    }
   ],
   "source": [
    "ens_params = {\n",
    "    'eval_metric' : 'auc',\n",
    "    'objective' : 'binary:logistic',\n",
    "    'max_depth' : 3,\n",
    "    'learning_rate' : 0.2,\n",
    "    'subsample' : 0.5,\n",
    "    'colsample_bytree' : 0.5,\n",
    "    'lambda' : 0\n",
    "}\n",
    "\n",
    "dpred_train = xgb.DMatrix(np.concatenate((xgb_ypred_train, ridge_ypred_train), 1), label=g_train_y)\n",
    "dpred_val = xgb.DMatrix(np.concatenate((xgb_ypred_val, ridge_ypred_val), 1), label=g_val_y)\n",
    "dpred_test = xgb.DMatrix(np.concatenate((xgb_ypred_test, ridge_ypred_test), 1))\n",
    "\n",
    "ens_bst = xgb.train(ens_params, dpred_train, 100, \n",
    "                 [(dpred_train, 'train'), (dpred_val, 'eval')],\n",
    "                 early_stopping_rounds=15, verbose_eval=10)\n",
    "ens_val_score = roc_auc_score(g_val_y, ens_bst.predict(dpred_val))\n",
    "ens_ypred_test = ens_bst.predict(dpred_test)\n",
    "print(f'Score: {ens_val_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "submission_df = DataFrame()\n",
    "submission_df['id'] = test_id\n",
    "submission_df['Predicted'] = ens_ypred_test\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f535': 1811.1331833,\n",
       " 'f205': 425.41577149999995,\n",
       " 'f315': 506.289062,\n",
       " 'f39': 92.33435825000001,\n",
       " 'f467': 154.19348584117643,\n",
       " 'f51': 35.0949173,\n",
       " 'f475': 425.498596,\n",
       " 'f457': 2899.2002,\n",
       " 'f27': 166.5925873277778,\n",
       " 'f501': 146.51183215,\n",
       " 'f247': 267.69910757,\n",
       " 'f416': 302.313965,\n",
       " 'f469': 82.11359074999999,\n",
       " 'f595': 356.5757273151516,\n",
       " 'f97': 203.11924360000003,\n",
       " 'f37': 198.44230643124996,\n",
       " 'f47': 111.29022092222222,\n",
       " 'f309': 140.80539974,\n",
       " 'f227': 113.046143,\n",
       " 'f114': 1398.14404,\n",
       " 'f49': 90.42183813333334,\n",
       " 'f395': 122.33252705,\n",
       " 'f161': 326.328979,\n",
       " 'f557': 1156.10474,\n",
       " 'f597': 238.56445300000001,\n",
       " 'f87': 57.809205559999995,\n",
       " 'f511': 347.54969800000003,\n",
       " 'f307': 138.53743678888887,\n",
       " 'f299': 44.020883500000004,\n",
       " 'f473': 71.09305665,\n",
       " 'f99': 140.2539216333333,\n",
       " 'f196': 40.437332839999996,\n",
       " 'f223': 84.3161011,\n",
       " 'f238': 78.922581175,\n",
       " 'f175': 65.3563232,\n",
       " 'f236': 114.30585606666666,\n",
       " 'f95': 65.41790358,\n",
       " 'f91': 34.40648463333334,\n",
       " 'f249': 57.610022900000004,\n",
       " 'f611': 96.86212556666668,\n",
       " 'f297': 61.47417438125,\n",
       " 'f170': 163.173721,\n",
       " 'f276': 34.079834,\n",
       " 'f305': 39.91676404,\n",
       " 'f183': 44.7829895,\n",
       " 'f33': 39.6829529,\n",
       " 'f251': 29.62638155333333,\n",
       " 'f89': 73.4230957,\n",
       " 'f67': 25.031562824999998,\n",
       " 'f172': 35.4063988,\n",
       " 'f85': 43.205252300000005,\n",
       " 'f459': 80.1238632,\n",
       " 'f593': 45.1987,\n",
       " 'f656': 46.67810368571429,\n",
       " 'f245': 46.5981989,\n",
       " 'f603': 46.34436325,\n",
       " 'f57': 24.6361485,\n",
       " 'f200': 32.479744,\n",
       " 'f629': 16.893790566666667,\n",
       " 'f81': 91.0169983,\n",
       " 'f239': 41.4911728,\n",
       " 'f341': 23.4396553,\n",
       " 'f577': 61.9381332,\n",
       " 'f207': 26.007907649999996,\n",
       " 'f243': 45.589817,\n",
       " 'f361': 33.9354324,\n",
       " 'f156': 12.1359253,\n",
       " 'f666': 9.94874573,\n",
       " 'f325': 10.010619649999999,\n",
       " 'f272': 44.8535233,\n",
       " 'f56': 50.0197678,\n",
       " 'f253': 25.2176803,\n",
       " 'f360': 22.8995557,\n",
       " 'f658': 17.037121799999998,\n",
       " 'f45': 23.682184833333334,\n",
       " 'f69': 24.63810635,\n",
       " 'f651': 18.01371,\n",
       " 'f600': 17.8128214,\n",
       " 'f598': 10.9377022,\n",
       " 'f439': 16.967678043333333,\n",
       " 'f641': 10.255188,\n",
       " 'f586': 30.063756000000005,\n",
       " 'f301': 23.823759733333333,\n",
       " 'f539': 22.72113035,\n",
       " 'f101': 14.218394600000002,\n",
       " 'f590': 17.0703812,\n",
       " 'f599': 28.516148115,\n",
       " 'f58': 18.44995548,\n",
       " 'f43': 20.24750855,\n",
       " 'f625': 20.7054214,\n",
       " 'f303': 17.1135941,\n",
       " 'f204': 34.243618,\n",
       " 'f614': 15.425788619999999,\n",
       " 'f201': 25.0952625,\n",
       " 'f609': 19.07295175,\n",
       " 'f107': 16.3877563,\n",
       " 'f615': 13.4990082,\n",
       " 'f206': 14.8821163,\n",
       " 'f670': 23.182131275,\n",
       " 'f255': 19.8715296,\n",
       " 'f415': 16.1637726,\n",
       " 'f639': 17.5239455,\n",
       " 'f363': 21.040451,\n",
       " 'f655': 11.4688072,\n",
       " 'f660': 19.820076,\n",
       " 'f555': 19.8455391,\n",
       " 'f637': 29.2372208,\n",
       " 'f34': 14.2893734,\n",
       " 'f667': 12.4836922,\n",
       " 'f471': 20.26980305,\n",
       " 'f198': 23.4460163,\n",
       " 'f654': 22.2960014,\n",
       " 'f674': 12.247776,\n",
       " 'f646': 26.0396023,\n",
       " 'f591': 5.91171265,\n",
       " 'f237': 17.016386025000003,\n",
       " 'f405': 15.0453062,\n",
       " 'f596': 19.870058775,\n",
       " 'f397': 24.3596458,\n",
       " 'f606': 19.5075645,\n",
       " 'f59': 9.927339065,\n",
       " 'f62': 20.1395607,\n",
       " 'f71': 14.9633617,\n",
       " 'f672': 18.678704250000003,\n",
       " 'f441': 20.4885693,\n",
       " 'f483': 18.3424492,\n",
       " 'f669': 18.19678595,\n",
       " 'f165': 14.6709547,\n",
       " 'f673': 16.94965745,\n",
       " 'f221': 34.3330307,\n",
       " 'f643': 10.2717686,\n",
       " 'f563': 20.5540733,\n",
       " 'f635': 17.2738934,\n",
       " 'f322': 10.8669291,\n",
       " 'f375': 16.6115837,\n",
       " 'f653': 25.519969,\n",
       " 'f628': 16.7115765,\n",
       " 'f613': 12.3534794,\n",
       " 'f519': 25.1999817,\n",
       " 'f75': 21.2627869,\n",
       " 'f122': 7.17707062,\n",
       " 'f607': 6.43775558,\n",
       " 'f605': 23.9306583,\n",
       " 'f112': 23.9446793,\n",
       " 'f63': 11.7073021,\n",
       " 'f195': 20.91423035,\n",
       " 'f254': 15.4886303,\n",
       " 'f649': 19.4604568,\n",
       " 'f424': 18.9862595,\n",
       " 'f154': 13.6042175,\n",
       " 'f129': 18.109805400000003,\n",
       " 'f125': 14.532661449999999,\n",
       " 'f634': 15.459566733333332,\n",
       " 'f68': 12.1246815,\n",
       " 'f352': 18.5761795,\n",
       " 'f479': 10.6122723,\n",
       " 'f121': 8.10202789,\n",
       " 'f316': 17.4306641,\n",
       " 'f542': 13.1501789,\n",
       " 'f166': 16.8545494,\n",
       " 'f324': 16.6180267,\n",
       " 'f534': 35.8763809,\n",
       " 'f191': 24.3049622,\n",
       " 'f633': 13.2021141,\n",
       " 'f647': 18.1321259,\n",
       " 'f286': 20.2969837,\n",
       " 'f621': 14.8005619,\n",
       " 'f663': 30.2308521,\n",
       " 'f623': 17.1996193,\n",
       " 'f675': 14.0330105,\n",
       " 'f55': 18.218895,\n",
       " 'f295': 14.7272186,\n",
       " 'f203': 13.2459154,\n",
       " 'f620': 12.3004112,\n",
       " 'f347': 19.3100357,\n",
       " 'f313': 12.3167267,\n",
       " 'f383': 16.63918255,\n",
       " 'f665': 13.9680929,\n",
       " 'f610': 19.136256250000002,\n",
       " 'f0': 7.78425741,\n",
       " 'f279': 12.29744337,\n",
       " 'f345': 9.58050632,\n",
       " 'f104': 10.379221,\n",
       " 'f326': 19.551178,\n",
       " 'f604': 11.8189316,\n",
       " 'f437': 14.0344305,\n",
       " 'f337': 6.44146395,\n",
       " 'f638': 14.9056606,\n",
       " 'f318': 10.9631481,\n",
       " 'f504': 11.8699665,\n",
       " 'f574': 22.5974789,\n",
       " 'f103': 18.5798607,\n",
       " 'f587': 11.2387142,\n",
       " 'f252': 11.174248460000001,\n",
       " 'f117': 16.0979996,\n",
       " 'f418': 14.9943466,\n",
       " 'f659': 4.71111679}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_sorted = []\n",
    "df_train_dropped = df_train.drop(columns=['id', 'y'])\n",
    "for l, v in fi.items():\n",
    "    cols_drop = df_train_dropped.columns\n",
    "    cols = df_train.columns\n",
    "    n = cols_drop[int(l[1:])]\n",
    "    if ',' not in n:\n",
    "        fi_sorted.append((v, n, '', ''))\n",
    "        continue\n",
    "    f1, f2, op = n.split(',')\n",
    "    fi_sorted.append((v, cols[int(f1)], cols[int(f2)], op))\n",
    "fi_sorted.sort(key=lambda x: x[0], reverse=True)\n",
    "df_fi = DataFrame()\n",
    "for i in range(4):\n",
    "    df_fi[['gain', 'f1', 'f2', 'op'][i]] = [x[i] for x in fi_sorted]\n",
    "df_fi.to_csv('important-features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi\n",
    "\n",
    "\n",
    "def add_features3(data, features):\n",
    "    for i in range(len(features)):\n",
    "        f1, f2, op = [features[x][i] for x in features.columns[1:]]\n",
    "        if op == '':\n",
    "            continue\n",
    "        if op == '+':\n",
    "            data[f'{f1},{f2},{op}'] = data[f1] + data[f2]\n",
    "        if op == '-':\n",
    "            data[f'{f1},{f2},{op}'] = data[f1] - data[f2]\n",
    "        if op == '*':\n",
    "            data[f'{f1},{f2},{op}'] = data[f1] * data[f2]\n",
    "        if op == '/':\n",
    "            data[f'{f1},{f2},{op}'] = data[f1] / data[f2]\n",
    "add_features3(df_train_dropped, df_fi)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

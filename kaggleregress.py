# -*- coding: utf-8 -*-
"""kaggleregress.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sfkYICyDhtXNIopxAZD9oVDTLDpOMBH0
"""

import pandas as pd
import numpy as np
from sklearn import linear_model
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn import ensemble
import math

def sigmoid(x):
  return 1 / (1 + np.exp(-x))

train = pd.read_csv("train.csv").drop(columns=['opened_position_qty ', 'closed_position_qty'])
test = pd.read_csv("test.csv").drop(columns=['opened_position_qty ', 'closed_position_qty'])

train['opened_position_qty '] = ((train['transacted_qty'] + train['d_open_interest'])/2).astype(int)
test['opened_position_qty '] = ((test['transacted_qty'] + test['d_open_interest'])/2).astype(int)

train['closed_position_qty'] = (train['transacted_qty'] - train['opened_position_qty ']).astype(int)
test['closed_position_qty'] = (test['transacted_qty'] - test['opened_position_qty ']).astype(int)

df_fi = pd.read_csv("important-features.csv")

df_train_dropped = train.drop(columns=['id', 'y'])
df_test_dropped = test.drop(columns=['id'])

def add_features3(data, features):
    for i in range(len(features)):
        f1, f2, op = [features[x][i] for x in features.columns[1:]]
        if op == '':
            continue
        if op == '+':
            data[f'{f1},{f2},{op}'] = data[f1] + data[f2]
        if op == '-':
            data[f'{f1},{f2},{op}'] = data[f1] - data[f2]
        if op == '*':
            data[f'{f1},{f2},{op}'] = data[f1] * data[f2]
        if op == '/':
            data[f'{f1},{f2},{op}'] = data[f1] / data[f2]

add_features3(df_train_dropped, df_fi)
add_features3(df_test_dropped, df_fi)

df_train_dropped['y'] = train['y']
train = df_train_dropped
train_y = train.y
train_x = train.drop(columns=['y']).fillna(0).replace(np.inf, 0)



num_folds = 10
kf = KFold(n_splits = num_folds)
r1 = linear_model.Ridge(alpha=30) # best when alpha = 30
r3 = linear_model.BayesianRidge()
# r4 = linear_model.OrthogonalMatchingPursuit()
# r5 = linear_model.PassiveAggressiveRegressor()
# r6 = linear_model.ElasticNet()
r7 = ensemble.AdaBoostRegressor(n_estimators = 100, learning_rate=5)
r8 = ensemble.RandomForestRegressor()
r9 = ensemble.BaggingRegressor()
# er = ensemble.StackingRegressor([('ridge', r1), ('lasso', r2), ('bayes', r3), ('omp', r4), ('par', r5), ('enet', r6)])
er = ensemble.StackingRegressor([('ridge', r1), ('adaboost', r7)])
train_errors = []
test_scores = []

from sklearn.model_selection import GridSearchCV

alphas = np.array([32, 33, 34])
# create and fit a ridge regression model, testing each alpha
model = linear_model.Ridge()
grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))
grid.fit(train_x, train_y)
print(grid)

# summarize the results of the grid search
print(grid.best_score_)
print(grid.best_estimator_.alpha)


# 0.07604925859682603
# 0.07604931609080774
#vscore = roc_auc_score(y_test, sigmoid(er.predict(x_test)))

from sklearn.model_selection import RandomizedSearchCV

param_dist = {
 'n_estimators': [100, 150, 200, 250, 300],
 'learning_rate' : [5, 10, 15],
 'loss' : ['linear']
 }

pre_gs_inst = RandomizedSearchCV(ensemble.AdaBoostRegressor(),
 param_distributions = param_dist,
 cv=3,
 n_iter = 10,
 n_jobs=-1)

pre_gs_inst.fit(train_x, train_y)

pre_gs_inst.best_params_

# Iterate over each fold

score = 0

data = train_x.to_numpy()
labels = train_y.to_numpy()
for train_index, test_index in kf.split(data):
    x_train, x_test = data[train_index], data[test_index]
    y_train, y_test = labels[train_index], labels[test_index]
    
    # Fit the training data
    er.fit(x_train, y_train)

    print(".")
    
    # Calculate the training error for this fold
    train_prediction = er.predict(x_train)
    train_error = 0
    for i in range(y_train.size):
        train_error += ((y_train[i] - train_prediction[i]) ** 2)
        
    # Calculate the validation score for this fold
    vscore = roc_auc_score(y_test, sigmoid(er.predict(x_test)))
    if vscore > score:
      best_model = er
      score = vscore
      
    print("Val score this fold: {}".format(vscore))
        
    train_errors.append(train_error / y_train.size)
    test_scores.append(vscore)

print("The average training error is {}".format(np.mean(train_errors)))
print("The average test score is {}".format(np.mean(test_scores)))

test_x = df_test_dropped

df_test = pd.read_csv('test.csv', index_col=0)
df_test['Predicted'] = sigmoid(best_model.predict(test_x.fillna(0).replace(np.inf, 0)))
df_test[['Predicted']].to_csv('submission1.csv')


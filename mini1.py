# -*- coding: utf-8 -*-
"""mini1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1njOsY4bwmwdg_LHmiMN7KbifTN6A7TLs
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import TensorDataset, DataLoader

from sklearn.metrics import roc_auc_score

TRAIN_SIZE = 500000

train_x = pd.read_csv('train.csv').drop(columns=['id', 'opened_position_qty ', 'closed_position_qty', 'y'])
train_y = pd.read_csv('train.csv')['y']

np.random.seed(50684)
perm = np.random.permutation(len(train_x))

df_train = TensorDataset(torch.tensor(train_x.iloc[perm[:TRAIN_SIZE]].to_numpy()), torch.tensor(train_y.iloc[perm[:TRAIN_SIZE]].to_numpy()))

val_x = torch.tensor(train_x.iloc[perm[TRAIN_SIZE:]].to_numpy())
val_y = train_y.iloc[perm[TRAIN_SIZE:]].to_numpy(dtype='double')

print(len(df_train))
print(df_train[0][0])
print(df_train[0][1])

print(val_x)
print(val_y)

model = nn.Sequential(  
    nn.Linear(24, 100),
    nn.LeakyReLU(),
    nn.Linear(100, 100),
    nn.LeakyReLU(),
    nn.Linear(100, 20),
    nn.LeakyReLU(),
    nn.Dropout(0.25),
    nn.Linear(20, 1)
)
print(model)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)
loss_fn = nn.BCEWithLogitsLoss()

train_loader = DataLoader(df_train, batch_size=1024, shuffle=True)

# Some layers, such as Dropout, behave differently during training

for epoch in range(10):
    model.train()
    for i, (data, target) in enumerate(train_loader):
        # Erase accumulated gradients
        optimizer.zero_grad()

        # Forward pass
        output = torch.squeeze(model(data.float()))

        # Calculate loss
        loss = loss_fn(output, target.float())

        # Backward pass
        loss.backward()
        
        # Weight update
        optimizer.step()

        if i % 55 == 0: print('.',end='')

    # Track loss each epoch
    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))

    # Validate
    model.eval()
    with torch.no_grad():
        print(model(val_x.float()))
        vscore = roc_auc_score(
                val_y,
                torch.sigmoid(torch.squeeze(model(val_x.float()))).numpy())
        
    # Track validation error each epoch
    print('Validation score: %.4f' % (vscore))

